{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff410b37-9e5c-494f-85f9-50904ae6e539",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This project investigates the factors of happiness. We use (source)'s definiton of happiness.\n",
    "We hypothesized on following factors: economic well being (in terms of GDP per capita), education (in terms of spending), internet propogation (area of coverage in cities), life expectency and other social factors.\\ \n",
    "We aim to answer what is the relationship between these factors in countries and citizens' happiness? and why do some countries report high levels of social well-being despite having a lower GDP?\\\n",
    "\\\n",
    "Our team consists of:\n",
    "* Aslbek: Data processor\n",
    "* Kassymkhan: Analyzer\n",
    "* Olzhas: Clusterer\n",
    "* Yernur: Plotter\n",
    "\\\n",
    "We divided our research into three parts:\n",
    "**Data processing** - to ensure that we have meaning and don't loose too much data\\\n",
    "**Data analysis** - We used various data visualization techniques and machine learning models in order to have insights\\\n",
    "**Findings and Evaluation.** Finally, using prompt engineering, we synthesized findings and generated AI-assisted policy insights.\\\n",
    "\\\n",
    "Prerequsites are put in the requirements.txt file.\\\n",
    "Our used data can be found in the data directory. It has raw/ and processed/ subdirectories which contain corresponding data.\\\n",
    "The dashboard is available on the dash_board.py file. In order to use it, just run it. It will open the dashboard in the browser.\\\n",
    "The non-code version of this file with all the charts can be found in the \"report.pdf\" file (credit for writing the report: Kassymkhan).\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342c5074-9ced-477e-8e32-3929f24e83b1",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b77019b-19c0-42fb-ae68-88609882bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data cleaning with KNN\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Polynomial regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Clusters\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Dashboard\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c732f-8463-4d8c-984f-7762169985e7",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "In order to keep the focus, we narrowed down our scope to statistics of year 2019.\n",
    "\n",
    "We used the follwing data:\n",
    "* Happiness data set (source: ) - this is a data from . Further, 'hap' for short;\n",
    "* GDP per capita (source: world bank) - this is a data from . Further, 'gdp' for short;\n",
    "* Education expenditure (source: ) - this is a data from . Further, 'edu' for short;\n",
    "* Life expectancy (source: ) - this is a data from . Further, 'exp' for short;\n",
    "* Inter penetrations (source: ) - this is a data from . Further, 'pen' for short.\n",
    "* \n",
    "\n",
    "After reading the files, we can immediately notice different number of rows in each data frame:\n",
    "* hap - 156 rows;\n",
    "* gdp - 266 rows;\n",
    "* hap - 266 rows;\n",
    "*\n",
    "\n",
    "This is because World Bank includes names of sets of regions, e.g. 'European Union', 'Caribbean Islands', 'World'.\\\n",
    "We will use left-merge to extend the hap data frame, as it has the most relevant name for regions.\\\n",
    "But first, we must prepare our data. We begin by introducing common column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18be9bda-6ee5-4e7e-b3c5-c58381e839bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/raw/happiness.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Happiness Dataset\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ================================\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m hap_raw = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./data/raw/happiness.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m hap = hap_raw.rename(columns={\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCountry or region\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mCountry\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mScore\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mHappiness score\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mGDP per capita\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mHappiness GDP\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m })\n\u001b[32m     12\u001b[39m hap[\u001b[33m\"\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[32m2019\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hkust/cs/ds/ds/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hkust/cs/ds/ds/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hkust/cs/ds/ds/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hkust/cs/ds/ds/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hkust/cs/ds/ds/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data/raw/happiness.csv'"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Happiness Dataset\n",
    "# ================================\n",
    "hap_raw = pd.read_csv(\"./data/raw/happiness.csv\")\n",
    "\n",
    "hap = hap_raw.rename(columns={\n",
    "    \"Country or region\": \"Country\",\n",
    "    \"Score\": \"Happiness score\",\n",
    "    \"GDP per capita\": \"Happiness GDP\",\n",
    "})\n",
    "\n",
    "hap[\"Year\"] = 2019\n",
    "hap = hap.drop(columns=[\"Year\", \"Overall rank\"])\n",
    "\n",
    "print(\"Happiness statistics:\")\n",
    "hap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010b010-6efc-49c4-b41c-696f279c19dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# GDP per capita\n",
    "# ================================\n",
    "gdp_raw = pd.read_excel(\"GDP.xls\")\n",
    "\n",
    "gdp = gdp_raw[[\"Country Name\", \"2019\"]]\n",
    "\n",
    "gdp = gdp.rename(columns={\n",
    "    \"Country Name\": \"Country\",\n",
    "    \"2019\": \"GDP per capita\"\n",
    "})\n",
    "\n",
    "print(\"GDP per capita\")\n",
    "gdp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b079cff-4dd2-4422-9d0d-99f280cdd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Education Expenditure\n",
    "# ================================\n",
    "edu_raw = pd.read_excel(\"Education.xls\")\n",
    "\n",
    "edu = edu_raw[[\"Country Name\", \"2019\"]]\n",
    "\n",
    "edu = edu.rename(columns={\n",
    "    \"Country Name\": \"Country\",\n",
    "    \"2019\": \"Education expenditure\"\n",
    "})\n",
    "\n",
    "print(\"Education expenditure:\")\n",
    "edu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a917f-244a-47d0-b3f2-8ad0f0502d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Life Expectancy Rates\n",
    "# ================================\n",
    "exp_raw=pd.read_excel(\"LifeExpectancy.xls\", header=3)\n",
    "id_vars = ['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code']\n",
    "exp_melted = exp_raw.melt(\n",
    "    id_vars=id_vars, \n",
    "    var_name='Year', \n",
    "    value_name='Life expectancy' # Set the value column name directly\n",
    ")\n",
    "\n",
    "exp_2019 = exp_melted[exp_melted['Year'] == '2019'].copy()\n",
    "exp_2019 = exp_2019.rename(columns={'Country Name': 'Country'})\n",
    "exp = exp_2019[['Country', 'Life expectancy']]\n",
    "exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73f48b-3982-4bf9-a7fb-5eb8d04b5733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Internet Penetration Rates\n",
    "# ================================\n",
    "net_raw = pd.read_excel(\"InternetRates.xls\", header=3)\n",
    "id_vars = ['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code']\n",
    "net_melted = net_raw.melt(\n",
    "    id_vars=id_vars,\n",
    "    var_name='Year',\n",
    "    value_name='Internet Users (% of Pop)'\n",
    ")\n",
    "net_2019 = net_melted[net_melted['Year'] == '2019'].copy()\n",
    "net_2019 = net_2019.rename(columns={'Country Name': 'Country'})\n",
    "net = net_2019[['Country', 'Internet Users (% of Pop)',]]\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce4b2ab-15c7-4756-b0d0-349def48fef3",
   "metadata": {},
   "source": [
    "## Addressing the key mismatches\n",
    "If we had merged the data above, we would have missing values in the final data frame even in rows where we have all the data.\\\n",
    "\\\n",
    "This is because of the mismatching naming of the countries and territories.\\\n",
    "For example, the hap data frame uses the label \"Russia\" for the 'gdp' label \"Russian Federation\".\\\n",
    "The left-merge algorithm would see these two labels as different rows, and wouldn't extend the relevant row.\\\n",
    "(credits for this observation and for its solution: Aslbek).\\\n",
    "\\\n",
    "In order to introduce more consistent naming, we identified all the mismatching territory names and made a new dictionary with corrections.\\\n",
    "World Bank's naming in the gdp data frame seemed more consistent, so we replaced some hap labels with gdp labels.\\\n",
    "\\\n",
    "Significantly missing blocks of data were extrapolated with a K-Nearest-Neighborhood algorithm (KNN).\\\n",
    "Shortly speaking, based on the existing data we \"predicted\" the missing values by taking an average of the K nearest neighbors.\\\n",
    "Neighborhood is defined by the closeness in other existing values.\\\n",
    "For example, we implemented KNN for Education expenditure column that lacked 23 rows.\\\n",
    "\\\n",
    "Finally, remaining missing values were filled by reasonably recent values.\\\n",
    "For example, for South Sudan \"2019 GDP per capita\" field was filled by \"2015 GDP per capita\".\\\n",
    "We also used external data in order to fill in minor missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d40abc9-2798-4582-b97b-eb412978ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missmatch between happienss and GDP data sets: \", set(hap['Country']) - set(gdp['Country']), \"\\n\")      # country names that 'hap' has, but 'gdp' doesn't\n",
    "print(\"Missmatch between happiness and Education data sets: \", set(hap['Country']) - set(edu['Country']), \"\\n\")\n",
    "print(\"Missmatch between happiness and Life Expectancy data sets: \", set(hap['Country']) - set(exp['Country']), \"\\n\")\n",
    "print(\"Missmatch between happiness and InternetRates data sets: \", set(hap['Country']) - set(net['Country']), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e35a1e-45c1-410e-934c-ea868fc3d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Correcting the labels\n",
    "# ================================\n",
    "\n",
    "# Values are the new, more universal names\n",
    "# e.g. 'Kyrgyzstan' --> 'Kyrgyz Republic' (World Bank)\n",
    "\n",
    "name_corrections = {\n",
    "\t'Congo (Brazzaville)': 'Congo, Dem. Rep.',\n",
    "\t'Congo (Kinshasa)': 'Congo, Rep.',\n",
    "\t'Czech Republic': 'Czechia',\n",
    "\t'Egypt': 'Egypt, Arab Rep.',\n",
    "\t'Gambia': 'Gambia, The',\n",
    "\t'Hong Kong': 'Hong Kong SAR, China',\n",
    "\t'Iran': 'Iran, Islamic Rep.',\n",
    "\t'Kyrgyzstan': 'Kyrgyz Republic',\n",
    "\t'Northern Cyprus': 'Northern Mariana Islands',\n",
    "\t'Palestinian Territories': 'West Bank and Gaza',\n",
    "\t'Russia': 'Russian Federation',\n",
    "\t'Slovakia': 'Slovak Republic',\n",
    "\t'Somalia': 'Somalia, Fed. Rep.',\n",
    "\t'South Korea': 'Korea, Rep.',\n",
    "\t'Syria': 'Syrian Arab Republic',\n",
    "\t'Trinidad & Tobago': 'Trinidad and Tobago',\n",
    "\t'Turkey': 'Turkiye',\n",
    "\t'Venezuela': 'Venezuela, RB',\n",
    "\t'Vietnam': 'Viet Nam',\n",
    "\t'Yemen': 'Yemen, Rep.',\n",
    "\t'Ivory Coast': 'Cote d\\'Ivoire',\n",
    "\t'Laos': 'Lao PDR',\n",
    "\t'Swaziland': 'Eswatini',\n",
    "}\n",
    "\n",
    "for k, v in name_corrections.items():\n",
    "    hap.loc[hap['Country'] == k, 'Country'] = v\n",
    "    edu.loc[edu['Country'] == k, 'Country'] = v\n",
    "    exp.loc[exp['Country'] == k, 'Country'] = v\n",
    "\n",
    "print(\"Missmatch between happienss and GDP per capita data sets:\")\n",
    "#set(hap['Country']) - set(gdp['Country'])           # Any left out names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2e548-657e-4dcf-8806-a208e35ed775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Left merging. Raw data frame\n",
    "# ================================\n",
    "df_raw = (\n",
    "    hap\n",
    "    .merge(gdp, on=[\"Country\"], how=\"left\")\n",
    "    .merge(edu, on=[\"Country\"], how=\"left\")\n",
    "    .merge(exp, on=[\"Country\"], how=\"left\")\n",
    "    .merge(net, on=[\"Country\"], how=\"left\")\n",
    ")\n",
    "\n",
    "print(\"Raw merged main data frame:\")\n",
    "df_raw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02f5f398-293c-47d6-9d9e-3867e3eee746",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c37a1-e6fa-459c-9a40-93d61a3d8432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Addressing the missing data\n",
    "# ================================\n",
    "df_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78558960-0008-42c3-a5c8-de0279c064ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Filling in the missing GDP per capita data \n",
    "# ================================\n",
    "gdp_filling = {\n",
    "    'Venezuela, RB': 15943.61,      # from 2014\n",
    "    'Yemen, Rep.': 633.89,          # from 2018\n",
    "    'South Sudan': 1080.15,         # from 2015\n",
    "    'Taiwan': 36000                 # Find a source\n",
    "}\n",
    "\n",
    "for k, v in gdp_filling.items():\n",
    "    df_raw.loc[df_raw['Country'] == k, 'GDP per capita'] = v\n",
    "\n",
    "# ================================\n",
    "# Filling in the missing Internet Propogation data \n",
    "# ================================\n",
    "net_filling={\n",
    "    # https://report.twnic.tw/2019/assets/download/TWNIC_TaiwanInternetReport_2019_EN.pdf\n",
    "    \"Taiwan\":85.6,\n",
    "    \"Kosovo\":89.443,                #from 2018\n",
    "    \"Northern Mariana Islands\":66,\n",
    "    \"Libya\":87.575,                 #from 2020\n",
    "    \"Tajikistan\":27.544,            #from 2020\n",
    "    \"Turkmenistan\":21.251,          #from 2017\n",
    "    \"Uganda\":7.4,                   #from 2020\n",
    "    \"Yemen, Rep.\":13.815,           #from 2020\n",
    "    \"Congo, Rep.\":24.821,           #from 2020\n",
    "    \"Somalia, Fed. Rep.\":15.024,    #from 2020\n",
    "    \"Venezuela, RB\":61.6,           #from 2017\n",
    "}\n",
    "\n",
    "for k, v in net_filling.items():\n",
    "    df_raw.loc[df_raw['Country'] == k, 'Internet Users (% of Pop)'] = v\n",
    "\n",
    "# ================================\n",
    "# Filling in the missing GDP per capita data \n",
    "# ================================\n",
    "exp_filling = {\n",
    "    # https://taiwantoday.tw/Society/Top-News/182736/Average-life-expectancy-hits-80.86-in-Taiwan\n",
    "    \"Taiwan\": 80.86,\n",
    "}\n",
    "\n",
    "for k,v in exp_filling.items():\n",
    "    df_raw.loc[df_raw[\"Country\"]== k, \"Life expectancy\"] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99392ec-8473-4b37-8d12-413a2c1170be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# We used KNN model to extrapolate education expenditure based on neighbors in remaining features \n",
    "# ================================\n",
    "features = df_raw.drop(columns=['Country'])\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "\n",
    "imputed_arr = imputer.fit_transform(features)\n",
    "\n",
    "imputed = pd.DataFrame(imputed_arr, columns=features.columns)\n",
    "\n",
    "imputed['Country'] = df_raw['Country']\n",
    "\n",
    "df_raw['Education expenditure'] = imputed['Education expenditure']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37943564-50a7-4bdc-87c6-7963ef275a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Processed data\n",
    "# ================================\n",
    "df = df_raw.sort_values(by=\"Happiness score\", ascending=False)\n",
    "\n",
    "print(\"Merged main data frame (ranked by happiness score):\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfda3d-830f-4290-b3bd-f1f34a680c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Checking for missing values\n",
    "# ================================\n",
    "print(\"Checking for missing values:\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c850750-272b-45f0-962e-80a72acfb249",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "In the subsection 2.1, we plotted the main statistics.\n",
    "In the subsection 2.2, we used regression models and MSE to evaluate their accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588a957-89ed-484b-9f67-448d83206feb",
   "metadata": {},
   "source": [
    "## General statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc371f7-95ea-48ca-a128-9be5f0b623a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Basic statistics\n",
    "# ================================\n",
    "print(\"Basic statistics:\")\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52573f5-7eed-41bc-a59a-831b05058617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Top 10 Countries by Happiness Score\n",
    "# ================================\n",
    "top_10 = df[[\"Country\", \"Happiness score\"]].head(10) # df is already sorted\n",
    "print(\"Top 10 happy countries:\")\n",
    "top_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb74bc-b07a-4387-a998-7ff57b9ccd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Bottom 10 Countries by Happiness Score\n",
    "# ================================\n",
    "bottom_10 = df[[\"Country\", \"Happiness score\"]].tail(10)\n",
    "print(\"Bottom 10 happy countires:\")\n",
    "bottom_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bfb403-263d-4fce-9d13-a364eabc9a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Correlation matrix (Heat map)\n",
    "# ================================\n",
    "corr_matrix = df.select_dtypes(include=['number']).corr()   # Other ways to draw the heat map?\n",
    "print(\"Correlation matrix:\")\n",
    "corr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f00e10-8844-4c7b-a148-ce67d7f0c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdGy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982bfe42-9c20-40b1-924e-563e94ee399f",
   "metadata": {},
   "source": [
    "## Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298aa4a-2d0e-4b7e-9343-7242504a650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant data\n",
    "x = df['GDP per capita']\n",
    "y = df['Happiness score']\n",
    "\n",
    "features = df.drop(columns = ['Country', 'Happiness score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f94ba4d-3eda-4916-b79d-762530f6b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Scatter plot for a single feature (GDP per capita)\n",
    "# ================================\n",
    "plt.title('Happiness score vs. GDP per capita')\n",
    "plt.xlabel('GDP per capita')\n",
    "plt.ylabel('Happiness index')\n",
    "plt.grid(True)\n",
    "plt.scatter(x, y)\n",
    "\n",
    "countries_to_label = {'Finland', 'China', 'Kazakhstan', 'United States', 'South Sudan', 'Mali'}\n",
    "\n",
    "for country in countries_to_label:\n",
    "    row = df[df['Country'] == country]\n",
    "    plt.text(row['GDP per capita'], row['Happiness score'], country, weight='bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f788a17-0f7f-4134-9207-17e4ab917d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Polynomial Regression. Correlation between GDP per capita and Happiness score\n",
    "# ================================\n",
    "# Keep x as a 1D Series for plotting and polyfit, but create a 2D feature array for sklearn\n",
    "X = x.values.reshape(-1, 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def mse_evaluation(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "degree = [1, 2, 3, 4]\n",
    "colors = ['red', 'orange', 'green', 'purple']\n",
    "\n",
    "x_line = np.linspace(x.min(), x.max(), 100)\n",
    "\n",
    "for deg, color in zip(degree, colors):\n",
    "    coeffs = np.polyfit(x, y, deg=deg)\n",
    "    poly = np.poly1d(coeffs)\n",
    "    \n",
    "    model = make_pipeline(\n",
    "        PolynomialFeatures(degree=deg, include_bias=False),\n",
    "        LinearRegression()\n",
    "    )\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    mse = mse_evaluation(model, x_test, y_test)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.grid(True)\n",
    "    plt.scatter(x, y)\n",
    "    \n",
    "    plt.title(f'Regression of degree {deg}')\n",
    "    plt.text(0.05, 0.95, f\"MSE = {mse:.3f}\", transform=plt.gca().transAxes, va='top')\n",
    "    plt.plot(x_line, poly(x_line), color=color, label=f\"Degree {deg}\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c1908-a055-46ac-8434-67693b326ece",
   "metadata": {},
   "source": [
    "### Logarithmic regression\n",
    "We have noticed that the pattern is rather exponential (logarithmic), therefore we used logarithmic regression model by transforning the x axis logarithmically. Then we applied linear regression model and obtained coefficents , the intercept and MSE. We found out that it was surprisingly fitting well. (credits for this discovery: Olzhas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b138139-e0cb-4ee0-be5b-83d87a129cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target\n",
    "X = df[['GDP per capita']]  # 2D DataFrame (single column)\n",
    "y = df['Happiness score']   # 1D Series\n",
    "\n",
    "# Only positive X (log requires >0) â€” use pandas indexing instead of numpy-style slicing\n",
    "mask = X['GDP per capita'] > 0\n",
    "X = X.loc[mask]\n",
    "y = y.loc[mask]\n",
    "\n",
    "# Log-transform X\n",
    "X_log = np.log(X)\n",
    "\n",
    "# Fit linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_log, y)\n",
    "\n",
    "# Predictions on actual data for MSE\n",
    "y_pred_train = model.predict(X_log)\n",
    "mse = mean_squared_error(y, y_pred_train)\n",
    "\n",
    "print(f\"Logarithmic model: MSE = {mse:.4f}\")\n",
    "\n",
    "# Smooth curve for plotting\n",
    "x_min = X['GDP per capita'].min()\n",
    "x_max = X['GDP per capita'].max()\n",
    "x_line = np.linspace(x_min, x_max, 200).reshape(-1,1)\n",
    "y_line = model.predict(np.log(x_line))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(X['GDP per capita'], y, alpha=0.6, label='Data')\n",
    "plt.plot(x_line.ravel(), y_line, color='red', label='Logarithmic fit')\n",
    "plt.xlabel(\"GDP per capita\")\n",
    "plt.ylabel(\"Happiness score\")\n",
    "plt.title(\"Logarithmic Regression: GDP vs Happiness\")\n",
    "plt.text(0.05, 0.95, f\"MSE = {mse:.3f}\", transform=plt.gca().transAxes, va='top')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d3fd7-13a8-43ec-9b3a-04320b785ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target\n",
    "X = df['GDP per capita'].values.reshape(-1, 1)\n",
    "y = df['Happiness score'].values\n",
    "\n",
    "# Remove non-positive values (log undefined)\n",
    "mask = X[:,0] > 0\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# Log-transform X for modeling\n",
    "X_log = np.log(X)\n",
    "\n",
    "# Fit linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_log, y)\n",
    "\n",
    "# Predictions on actual data (for MSE)\n",
    "y_pred = model.predict(X_log)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(f\"Logarithmic regression MSE: {mse:.4f}\")\n",
    "\n",
    "# Smooth curve for plotting\n",
    "x_line = np.linspace(X.min(), X.max(), 200).reshape(-1,1)\n",
    "y_line = model.predict(np.log(x_line))\n",
    "\n",
    "# Plot scatter + regression curve\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(X, y, alpha=0.6, label='Data')\n",
    "plt.plot(x_line, y_line, color='red', label='Logarithmic fit')\n",
    "\n",
    "# Log-scale X-axis for visual linearization\n",
    "plt.xscale('log')\n",
    "\n",
    "# Display MSE on plot\n",
    "plt.text(0.05, 0.95, f\"MSE = {mse:.3f}\", transform=plt.gca().transAxes, va='top')\n",
    "\n",
    "plt.xlabel(\"GDP per capita (log scale)\")\n",
    "plt.ylabel(\"Happiness score\")\n",
    "plt.title(\"Logarithmic Regression: GDP vs Happiness\")\n",
    "plt.grid(True, which='both', ls='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a56fadd-37ba-420f-baff-30298b0060e0",
   "metadata": {},
   "source": [
    "## Feature correlation\n",
    "We examined various relationships between features and the happiness index.\n",
    "There are multiple scatter plots with linear regression line and compared their correlation matirx. \n",
    "The results were sorted and are as follows:\n",
    "    * The most significant correlation:\n",
    "    * Less significant coorelation:\n",
    "    * Weak correlation:\n",
    "\n",
    "One can note that there are no negative correlation even amng insignificant ones. This shows that the feature choice is quite lucky.\n",
    "\n",
    "Next, is a general linear regression snippet that captures the relationships between all the features. We considered it noteworkthy to write down it r^2 and MSE evaluation scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a2523-eb3a-4f6a-b974-3ca17ea52cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in features.drop(columns = ['GDP per capita']).columns:\n",
    "    X_col = df[[col_name]].values\n",
    "    y = df['Happiness score'].values\n",
    "    \n",
    "    # Fit linear model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_col, y)\n",
    "    \n",
    "    # MSE on training data\n",
    "    y_pred = model.predict(X_col)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    print(f\"{col_name}: MSE = {mse:.3f}\")\n",
    "    \n",
    "    # Scatter plot + regression line\n",
    "    plt.figure()\n",
    "    plt.scatter(X_col, y, alpha=0.6)\n",
    "    x_line = np.linspace(X_col.min(), X_col.max(), 200).reshape(-1,1)\n",
    "    y_line = model.predict(x_line)\n",
    "    plt.plot(x_line, y_line, color='red', label='Linear fit')\n",
    "    \n",
    "    plt.title(f\"Happiness vs {col_name}\")\n",
    "    plt.xlabel(col_name)\n",
    "    plt.ylabel(\"Happiness score\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c2f61-9771-4f65-ab47-14d3c3964aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Linear Regression Model for Multiple Features\n",
    "# ================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"R^2 score: \", r2)\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    \"Feature\": features.columns,\n",
    "    \"Coefficient\": lr.coef_\n",
    "}).sort_values(\"Coefficient\", ascending=False)\n",
    "\n",
    "print(\"\\nFeatures' Importance (Linear Regression Coefficients):\")\n",
    "print(coefficients)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(coefficients[\"Feature\"], coefficients[\"Coefficient\"], color='skyblue')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Coefficient Value\")\n",
    "plt.title(\"Feature Importance (Linear Regression Coefficients)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74f7182-a6c0-4964-a1cd-9243a94c13fe",
   "metadata": {},
   "source": [
    "## Clusters\n",
    "\n",
    "We used KMeans as clustering model. (Task maybe try others?)\n",
    "Our model has divided the model into three clusters.\n",
    "We used GDP per capita vs. Happiness scores to illustrate those clusters, although they used more features.\n",
    "\n",
    "Task: what are those models. Describe them\n",
    "Task: Put the centroids.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c38288-f057-48dc-a8e7-addb898927c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Clustering\n",
    "# ================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "df_cluster = df.copy()\n",
    "df_cluster['Cluster'] = clusters\n",
    "\n",
    "plt.scatter(df_cluster['GDP per capita'], df_cluster['Happiness score'], c = df_cluster['Cluster'], cmap='Set1')\n",
    "plt.xlabel('GDP per capita')\n",
    "plt.ylabel('Happiness score')\n",
    "plt.title('Country clusters')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show\n",
    "\n",
    "\n",
    "for country in countries_to_label:\n",
    "    row = df[df['Country'] == country]\n",
    "    plt.text(row['GDP per capita'].values[0], row['Happiness score'].values[0], country, fontsize=9, weight='bold')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e632c-bc41-432e-adb0-67af603e20d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in features.drop(columns = ['GDP per capita']).columns:\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(df_cluster[col], df_cluster['Happiness score'], c = df_cluster['Cluster'], cmap='Set1')\n",
    "    plt.xlabel(f\"{col}\")\n",
    "    plt.ylabel('Happiness score')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    \n",
    "    \n",
    "    for country in countries_to_label:\n",
    "        row = df[df['Country'] == country]\n",
    "        plt.text(row[col].values[0], row['Happiness score'].values[0], country, fontsize=9, weight='bold')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4ae1a-53cd-4d99-a324-68ba0f3d85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_dict = {}\n",
    "\n",
    "for c in sorted(df_cluster['Cluster'].unique()):\n",
    "    clusters_dict[c] = df_cluster[df_cluster['Cluster'] == c]['Country'].tolist()\n",
    "\n",
    "for c, countries in clusters_dict.items():\n",
    "    print(f\"Cluster {c}:\")\n",
    "    print(countries)\n",
    "    print(\"\\n\")\n",
    "\n",
    "'''\n",
    "cluster_summary = df_cluster.groupby('Cluster')\n",
    "len([features.columns])\n",
    "print(cluster_summary)\n",
    "'''\n",
    "\n",
    "centroids = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=features.columns)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14368c58-f72c-487f-83a0-45d749f19d2c",
   "metadata": {},
   "source": [
    "# Evaluation of the Report\n",
    "\n",
    "There are limitations: \n",
    "only 2019, \n",
    "incomplete data (Education expenditure, GDP per capita), \n",
    "extrapolations when handlind missing values, \n",
    "only three data sets\n",
    "\n",
    "\n",
    "This study could extended. \n",
    "Other years and global trends, for example comparing with pandemic times.\n",
    "Other features such as climate, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9783260-e816-4689-850d-c11f9c8ca824",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We have identified ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042d2dee-676f-4dc3-ab66-f754553c02be",
   "metadata": {},
   "source": [
    "# Dashboard\n",
    "The interactive dashboard below perfectly summarizes our analysis. \n",
    "The reader can hover over regions and see their happiness scores.\n",
    "The lighter the color, the happier the region is.\n",
    "(credits for drawing the map: Yernur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76125a9c-03cf-44b0-aa33-fd6d181af4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(hap[[\"Country\", \"Happiness score\"]], \n",
    "                    locations='Country', \n",
    "                    color='Happiness score',\n",
    "                    locationmode='country names', \n",
    "                    color_continuous_scale=px.colors.sequential.speed_r,\n",
    "                    title='Global Happiness Score (2019)',\n",
    "                    height=720\n",
    "                   )\n",
    "\n",
    "fig.update_xaxes(automargin=True)\n",
    "fig.update_yaxes(automargin=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d4651c-c979-43a6-a876-ff4a0f7a9734",
   "metadata": {},
   "source": [
    "http://localhost:8051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1cc5d-32c7-401f-afad-dd9f7a61b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
